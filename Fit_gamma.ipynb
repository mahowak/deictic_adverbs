{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_ib import RunIB\n",
    "from enumerate_lexicons import get_random_lexicon\n",
    "import enumerate_lexicons as el\n",
    "from ib import ib, mi, information_plane\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "from stirling import stirling\n",
    "import enumerate_lexicons\n",
    "pd.options.display.max_rows = 250\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from scipy.stats import linregress\n",
    "import scipy\n",
    "from d_ib import dib\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit $\\gamma$ for each real lexicon\n",
    "\n",
    "NOTE: in this notebook, we have to define the metric as \n",
    "\n",
    "$J_{IB} = I[M;U] - \\gamma I[M;W]$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsp = np.logspace(0,2,num = 1500)\n",
    "mu = 0.3\n",
    "num_dists = 3\n",
    "pgs_dists = [0,0.789,-1.315]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_curve(mu, pgs = pgs_dists):\n",
    "    i = 0\n",
    "    curve = pd.DataFrame(data = {'gamma': [],\n",
    "                            'informativity' : [],\n",
    "                            'complexity' : []})\n",
    "    qW_M = [None] * logsp.shape[0]\n",
    "    \n",
    "    for gamma in logsp:\n",
    "        informativity = None\n",
    "        complexity = None\n",
    "        F = None\n",
    "        x = RunIB(mu, gamma, num_dists, pgs)\n",
    "        for num_words in range(2, 3*num_dists + 1):\n",
    "            q_w_m_temp = ib(x.prior, x.prob_u_given_m, num_words, gamma, num_iter = 100) # fix the ib script\n",
    "            informativity_temp, complexity_temp = information_plane(x.prior, x.prob_u_given_m, q_w_m_temp)\n",
    "            F_temp = complexity_temp - gamma * informativity_temp\n",
    "            if num_words == 2:\n",
    "                F = F_temp\n",
    "                informativity = informativity_temp\n",
    "                complexity = complexity_temp\n",
    "                q_w_m = q_w_m_temp\n",
    "            else:\n",
    "                if F_temp < F:\n",
    "                    F = F_temp\n",
    "                    informativity = informativity_temp\n",
    "                    complexity = complexity_temp\n",
    "                    q_w_m = q_w_m_temp\n",
    "            \n",
    "        curve = curve.append({'gamma': gamma, 'informativity': informativity,\n",
    "                             'complexity': complexity}, ignore_index=True)\n",
    "        qW_M[i] = q_w_m\n",
    "        i+=1\n",
    "        \n",
    "    return curve, qW_M\n",
    "            \n",
    "obj = gamma_curve(mu)\n",
    "curve = obj[0]\n",
    "qW_M = obj[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_curve_det(mu, pgs = pgs_dists):\n",
    "    i = 0\n",
    "    curve_det = pd.DataFrame(data = {'gamma': [],\n",
    "                            'informativity' : [],\n",
    "                            'complexity' : []})\n",
    "    qW_M_det = [None] * logsp.shape[0]\n",
    "    \n",
    "    for gamma in logsp:\n",
    "        informativity = None\n",
    "        complexity = None\n",
    "        F = None\n",
    "        x = RunIB(mu, gamma, 3, pgs)\n",
    "        for num_words in range(2,10):\n",
    "            q_w_m_temp = ib(x.prior, x.prob_u_given_m, num_words, gamma, num_iter = 10, temperature = 0.01)\n",
    "            informativity_temp, complexity_temp = information_plane(x.prior, x.prob_u_given_m, q_w_m_temp)\n",
    "            F_temp = complexity_temp - gamma * informativity_temp\n",
    "            if num_words == 2:\n",
    "                F = F_temp\n",
    "                informativity = informativity_temp\n",
    "                complexity = complexity_temp\n",
    "                q_w_m = q_w_m_temp\n",
    "            else:\n",
    "                if F_temp < F:\n",
    "                    F = F_temp\n",
    "                    informativity = informativity_temp\n",
    "                    complexity = complexity_temp\n",
    "                    q_w_m = q_w_m_temp\n",
    "            \n",
    "        curve_det = curve_det.append({'gamma': gamma, 'informativity': informativity,\n",
    "                             'complexity': complexity}, ignore_index=True)\n",
    "        qW_M_det[i] = q_w_m\n",
    "        i+=1\n",
    "        \n",
    "    return curve_det, qW_M_det\n",
    "            \n",
    "obj = gamma_curve_det(mu)\n",
    "curve_det = obj[0]\n",
    "qW_M_det = obj[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes from Kyle\n",
    "def getEquidistantPoints(p1, p2, parts):\n",
    "    return zip(np.linspace(p1[0], p2[0], parts+1),\n",
    "               np.linspace(p1[1], p2[1], parts+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = RunIB(mu,2,num_dists, pgs_dists)\n",
    "num_meanings = 3 * num_dists\n",
    "lexicon_size_range = range(2, num_meanings + 1)\n",
    "sim_lex_dict = {lexicon_size: [lexicon for lexicon in enumerate_lexicons.enumerate_possible_lexicons(num_meanings, lexicon_size)] for \n",
    "        lexicon_size in lexicon_size_range}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = x.get_real_langs(num_meanings)\n",
    "\n",
    "df = pd.DataFrame([{dm: l[1].argmax(axis=1)[dm_num]\n",
    "                        for dm_num, dm in enumerate(x.deictic_index)} for l in lexicons])\n",
    "information_plane_list = [information_plane(x.prior, x.prob_u_given_m, l[1]) for l in lexicons]\n",
    "df[\"I[U;W]\"] = [l[0] for l in information_plane_list]\n",
    "df[\"I[M;W]\"] = [l[1] for l in information_plane_list]\n",
    "df[\"Language\"] = [l[0] for l in lexicons]\n",
    "df[\"Area\"] = [l[2] for l in lexicons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons_sim = []\n",
    "for lexicon_size in range(2, num_meanings+1):\n",
    "    all_lex = sim_lex_dict[lexicon_size]\n",
    "    lexicons_sim += [(\"simulated\", l[1], \"simulated\") for l in all_lex]\n",
    "\n",
    "df_sim = pd.DataFrame([{dm: l[1].argmax(axis=1)[dm_num]\n",
    "                        for dm_num, dm in enumerate(x.deictic_index)} for l in lexicons_sim])\n",
    "\n",
    "information_plane_list_sim = [information_plane(x.prior, x.prob_u_given_m, l[1]) for l in lexicons_sim]\n",
    "df_sim[\"I[U;W]\"] = [l[0] for l in information_plane_list_sim]\n",
    "df_sim[\"I[M;W]\"] = [l[1] for l in information_plane_list_sim]\n",
    "df_sim[\"Language\"] = [l[0] for l in lexicons_sim]\n",
    "df_sim[\"Area\"] = [l[2] for l in lexicons_sim]\n",
    "\n",
    "sim_only_plane = np.array([[l[0], l[1]] for l in information_plane_list_sim])\n",
    "real_only_plane = np.array(df[[\"I[U;W]\", \"I[M;W]\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vertices = ConvexHull(sim_only_plane).vertices\n",
    "pv = sim_only_plane[vertices] # this is the hull\n",
    "resid = pv[:, 1] - (linregress(sim_only_plane).intercept +\n",
    "                    pv[:, 0] * linregress(sim_only_plane).slope)\n",
    "vertices = vertices[resid < 0]  # just the bottom part of hull\n",
    "\n",
    "# fill in between the points\n",
    "verts = []\n",
    "for i, j in zip(pv, np.array(list(pv[1:, :]) + list([pv[0, :]]))):\n",
    "    if i[0] < j[0]:\n",
    "        verts += list(getEquidistantPoints(i, j, 100))\n",
    "verts = np.array(verts)\n",
    "\n",
    "dists = euclidean_distances(real_only_plane, verts).min(axis=1)\n",
    "dists_sim = euclidean_distances(sim_only_plane, verts).min(axis=1)\n",
    "\n",
    "df[\"dist_to_hull\"] = dists\n",
    "df_sim[\"dist_to_hull\"] = dists_sim\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df_sim.loc[df_sim[\"dist_to_hull\"] < 0.0001][\"I[U;W]\"], \n",
    "         df_sim.loc[df_sim[\"dist_to_hull\"] < 0.0001][\"I[M;W]\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sheets/real_lexicons_fit_mu_' + str(mu) + '_pgs_' + \"_\".join([str(pgs) for pgs in pgs_dists]) + 'num_dists_' + str(num_dists) + '.csv')\n",
    "df_sim.to_csv('sheets/sim_lexicons_fit_mu_'+ str(mu) + '_pgs_' + \"_\".join([str(pgs) for pgs in pgs_dists]) + 'num_dists_' + str(num_dists) +'.csv')\n",
    "curve.to_csv('sheets/ib_curve_non_deter_mu_' + str(mu) + '_pgs_' + \"_\".join([str(pgs) for pgs in pgs_dists]) + 'num_dists_' + str(num_dists) +'.csv')\n",
    "curve_det.to_csv('sheets/ib_curve_deter_mu_' + str(mu) + '_pgs_' + \"_\".join([str(pgs) for pgs in pgs_dists]) + 'num_dists_' + str(num_dists) +'.csv')\n",
    "\n",
    "#df_verts = pd.DataFrame({\"informativity\": verts[:,0], \"complexity\": verts[:,1]})\n",
    "#df_verts.to_csv('sheets/ib_frontier_mu_'+ str(mu) + '_pgs_' + \"_\".join([str(pgs) for pgs in pgs_dists])+ 'num_dists_' + str(num_dists) +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
